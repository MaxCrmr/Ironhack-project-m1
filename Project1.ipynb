{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc03e35a-d2e5-4e14-be3d-4a862314520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "resident-nation",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IronhackSpider:\n",
    "    \"\"\"\n",
    "    This is the constructor class to which you can pass a bunch of parameters. \n",
    "    These parameters are stored to the class instance variables so that the\n",
    "    class functions can access them later.\n",
    "    \n",
    "    url_pattern: the regex pattern of the web urls to scape\n",
    "    pages_to_scrape: how many pages to scrape\n",
    "    sleep_interval: the time interval in seconds to delay between requests. If <0, requests will not be delayed.\n",
    "    content_parser: a function reference that will extract the intended info from the scraped content.\n",
    "    \"\"\"\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrape the content of a single url.\n",
    "    \"\"\"\n",
    "    def scrape_url(self, url):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            content = self.get_response_content(response)\n",
    "            if not self.content_parser is None:\n",
    "                result = self.content_parser(content)\n",
    "            else:\n",
    "                result = content\n",
    "        except:\n",
    "            result = None\n",
    "        self.output_results(result)\n",
    "        \n",
    "    def get_response_content(self, r):\n",
    "        if (r.status_code == 200):\n",
    "            return r.content\n",
    "        return False\n",
    "    \n",
    "    \"\"\"\n",
    "    Export the scraped content. Right now it simply print out the results.\n",
    "    But in the future you can export the results into a text file or database.\n",
    "    \"\"\"\n",
    "    def output_results(self, r):\n",
    "        for v in r:\n",
    "            with open('rank.csv','a',newline='', encoding='utf-8') as fichiercsv:\n",
    "                writer=csv.writer(fichiercsv)\n",
    "                writer.writerow(v)\n",
    "#         print(r)\n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\"\n",
    "    def kickstart(self):\n",
    "        global weeks\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            try:\n",
    "                if i < 10:\n",
    "                        self.scrape_url(self.url_pattern[0] % i)\n",
    "                else:\n",
    "                        self.scrape_url(self.url_pattern[1] % i)\n",
    "            except:\n",
    "                weeks += 1\n",
    "                pass\n",
    "            if self.sleep_interval > 0:\n",
    "                time.sleep(self.sleep_interval)\n",
    "\n",
    "\n",
    "URL_PATTERN = ['http://www.chartsinfrance.net/charts/200%s/singles.php', 'http://www.chartsinfrance.net/charts/20%s/singles.php'] # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 52 # how many webpages to scrape\n",
    "weeks = 1\n",
    "\n",
    "\"\"\"\n",
    "This is a custom parser function you will complete in the challenge.\n",
    "Right now it simply returns the string passed to it. But in this lab\n",
    "you will complete this function so that it extracts the quotes.\n",
    "This function will be passed to the IronhackSpider class.\n",
    "\"\"\"\n",
    "def quotes_parser(content):\n",
    "    soup = BeautifulSoup(content, \"html\")\n",
    "    songs = [[elements.find_all('a')[0].text, elements.find_all('a')[1].text] for elements in soup.find_all('div',{'class':'b572'})]\n",
    "    global weeks\n",
    "    results = [[str(weeks), str(i + 1), songs[i][0], songs[i][1]] for i in range(50)]    \n",
    "    weeks += 1\n",
    "    return results\n",
    "\n",
    "# Instantiate the IronhackSpider class\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=quotes_parser)\n",
    "\n",
    "# Start scraping jobs\n",
    "\n",
    "entete = ['Week', 'Top', 'Artist', 'Track']\n",
    "f = open('rank.csv', 'w')\n",
    "ligneEntete = \",\".join(entete) + \"\\n\"\n",
    "f.write(ligneEntete)\n",
    "f.close()\n",
    "\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffe1de16-14b5-44b8-9318-e03493e332b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fd = pd.read_csv('rank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "timely-intersection",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv('temperature-quotidienne-departementale.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dced6b3c-5547-45ea-bfad-39d3f0049475",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df['date_obs'] = pd.to_datetime(temp_df['date_obs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13227b29-871d-4952-931f-00e4a772d931",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df2 = temp_df[(temp_df['date_obs'] >= '27-12-2019') & (temp_df['date_obs'] <= '17-12-2020')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20c52b2b-eed2-44c0-bfca-26454ca20536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-8a3ecc38046d>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df2.sort_values(by='date_obs', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "temp_df2.sort_values(by='date_obs', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d03a880-248f-42ef-b21b-fe18c5a93fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_temp_week = temp_df2.groupby(temp_df2.date_obs.dt.strftime('%W')).tmoy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa984c2d-4b80-4740-927d-27c6428945e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtw_df = pd.DataFrame([[i + 1, mean_temp_week[i]] for i in range(len(mean_temp_week))], columns = ['Week', 'Mean Temperature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba56f764-7fe4-4060-9cbb-9acd82c9f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tracks = pd.read_csv('rank.csv')\n",
    "tracks = [tracks for tracks in top_tracks['Track']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91946686-0fe5-468c-8e6b-7dcb0fb3fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('spotify_token.txt','r')\n",
    "spotify_token = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6652cd2c-8499-4cdc-ab38-af196061781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_ids(track):\n",
    "    track = urllib.parse.quote(track)\n",
    "    try:\n",
    "        search_track_json = requests.get(f'https://api.spotify.com/v1/search?q={track}&type=track&market=FR&limit=1', \n",
    "                                headers={'Accept': 'application/json', \n",
    "                                         \"Content-Type\": \"application/json\",\n",
    "                                        'Authorization': f'Bearer {spotify_token}'}).json()\n",
    "        return search_track_json['tracks']['items'][0]['id']\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7d3579f-6fa4-4034-8315-2916c81bbb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(ids):\n",
    "    try:\n",
    "        tracks_features_json = requests.get(f'https://api.spotify.com/v1/audio-features?ids={ids}', \n",
    "                                headers={'Accept': 'application/json', \n",
    "                                         \"Content-Type\": \"application/json\",\n",
    "                                        'Authorization': f'Bearer {spotify_token}'}).json()\n",
    "        return tracks_features_json['audio_features'][0]['valence']\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "accae988-f4dd-4203-99f4-1c364578d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_id_val = [[track, search_ids(track), find_features(search_ids(track))] for track in set(tracks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "110b322d-cc94-48c6-83fd-23f8ba7d3489",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiv_df = pd.DataFrame(track_id_val, columns = ['Track', 'Id', 'Valence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "456ab566-bfca-450d-b1f0-cfc1cae67f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_track_valence = pd.merge(top_fd, \n",
    "                      tiv_df, \n",
    "                      on ='Track', \n",
    "                      how ='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1685994a-7f07-423e-8fe4-9c92ebcd61a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_track_valence_temp = pd.merge(top_track_valence, mtw_df, on ='Week', how ='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12929a94-c522-43dc-8b46-a304f70d8e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Temperature</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Temperature</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valence</th>\n",
       "      <td>0.029442</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Mean Temperature   Valence\n",
       "Mean Temperature          1.000000  0.029442\n",
       "Valence                   0.029442  1.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Is there a correlation between \n",
    "top_track_valence_temp[['Mean Temperature', 'Valence']].corr()\n",
    "#There is a very small positive correlation beetween average temperature and the valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5e188a-a44e-4dee-883b-44d9b4cacd01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
